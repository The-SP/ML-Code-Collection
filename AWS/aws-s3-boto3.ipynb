{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python, Boto3, and AWS S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resource provides access to AWS services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_resource = boto3.resource('s3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display all buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- dsl-smartkhata-backups\n",
      "- image-service-deployment-a15dacef74\n",
      "- image-service-dsl-bin-production\n",
      "- pankaj-blog\n",
      "- sp-test-03ebd6dd-efe7-4e49-aee5-a9d4a77fa19a\n",
      "- sp-test-42072178-663e-4e5d-b57e-5b22f467e608\n"
     ]
    }
   ],
   "source": [
    "for bucket in s3_resource.buckets.all():\n",
    "    print(f'- {bucket.name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create s3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "def create_bucket_name(bucket_prefix):\n",
    "    \"\"\"\n",
    "    Create a unique bucket name and add a prefix to specify what each bucket is for.\n",
    "    \"\"\"\n",
    "    return ''.join([bucket_prefix, str(uuid.uuid4())])\n",
    "\n",
    "\n",
    "def create_bucket(bucket_prefix, s3_resource):\n",
    "    bucket_name = create_bucket_name(bucket_prefix)\n",
    "    bucket_response = s3_resource.create_bucket(\n",
    "        Bucket=bucket_name\n",
    "    )\n",
    "    return bucket_name, bucket_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sp-test-2e13fb42-57a6-47d3-9d3f-795bcb8a4975'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_bucket_name('sp-test-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name, bucket_response = create_bucket(bucket_prefix='sp-test-', s3_resource=s3_resource)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sp-test-42072178-663e-4e5d-b57e-5b22f467e608\n",
      "s3.Bucket(name='sp-test-42072178-663e-4e5d-b57e-5b22f467e608')\n"
     ]
    }
   ],
   "source": [
    "print(bucket_name)\n",
    "print(bucket_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-dsl-smartkhata-backups\n",
      "-image-service-deployment-a15dacef74\n",
      "-image-service-dsl-bin-production\n",
      "-pankaj-blog\n",
      "-sp-test-03ebd6dd-efe7-4e49-aee5-a9d4a77fa19a\n",
      "-sp-test-42072178-663e-4e5d-b57e-5b22f467e608\n"
     ]
    }
   ],
   "source": [
    "for bucket in s3_resource.buckets.all():\n",
    "    print(f'-{bucket.name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting S3 buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets_to_delete = [\n",
    "    \"sp-test-387b9fdd-92eb-40fe-918f-6027af13cd50\",\n",
    "    \"sp-test-40ade20e-4504-49fd-840c-b7d8208d4766\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_s3_buckets(buckets_to_delete):\n",
    "    for bucket_name in buckets_to_delete:\n",
    "        bucket= s3_resource.Bucket(bucket_name)\n",
    "        \n",
    "        # Check if the bucket exists\n",
    "        if bucket.creation_date is None:\n",
    "            print(f'Bucket {bucket_name} does not exist, skipping.')\n",
    "            continue\n",
    "            \n",
    "        # Deleting all bucket's objects first\n",
    "        for obj in bucket.objects.all():\n",
    "            obj.delete()\n",
    "                       \n",
    "        # Now the bucket should be empty, so delete it\n",
    "        try:\n",
    "            bucket.delete()\n",
    "            print(f\"Deleted bucket {bucket_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting bucket {bucket_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket sp-test-387b9fdd-92eb-40fe-918f-6027af13cd50 does not exist, skipping.\n",
      "Bucket sp-test-40ade20e-4504-49fd-840c-b7d8208d4766 does not exist, skipping.\n"
     ]
    }
   ],
   "source": [
    "delete_s3_buckets(buckets_to_delete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Bucket and Object Instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'first.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_bucket = s3_resource.Bucket(name=bucket_name)\n",
    "# first_object = s3_resource.Object(bucket_name=bucket_name, key=file_name)\n",
    "first_object = first_bucket.Object(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uploading a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_object.upload_file(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traversals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bucket traversal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dsl-smartkhata-backups\n",
      "image-service-deployment-a15dacef74\n",
      "image-service-dsl-bin-production\n",
      "pankaj-blog\n",
      "sp-test-03ebd6dd-efe7-4e49-aee5-a9d4a77fa19a\n",
      "sp-test-42072178-663e-4e5d-b57e-5b22f467e608\n"
     ]
    }
   ],
   "source": [
    "for bucket in s3_resource.buckets.all():\n",
    "    print(bucket.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Object traversal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first.txt\n"
     ]
    }
   ],
   "source": [
    "for obj in first_bucket.objects.all():\n",
    "    print(obj.key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first.txt STANDARD 2024-05-23 12:01:36+00:00\n",
      "None {}\n"
     ]
    }
   ],
   "source": [
    "for obj in first_bucket.objects.all():\n",
    "    subsrc = obj.Object()\n",
    "    print(obj.key, obj.storage_class, obj.last_modified)\n",
    "    print(subsrc.version_id, subsrc.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload a file to S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_file_to_s3(file_path, bucket_name, object_name=None):\n",
    "    if object_name is None:\n",
    "        object_name = file_path.split('/')[-1]\n",
    "\n",
    "    s3_resource = boto3.resource('s3')\n",
    "    bucket = s3_resource.Bucket(bucket_name)\n",
    "\n",
    "    try:\n",
    "        bucket.upload_file(file_path, object_name)\n",
    "        print(f\"File '{file_path}' uploaded successfully to bucket '{bucket_name}' with key '{object_name}'\")\n",
    "    except Exception as e:\n",
    "        print(f'Error uploading file to S3: {e}')\n",
    "        \n",
    "        \n",
    "def upload_file_to_s3_using_client(file_path, bucket_name, object_name=None):\n",
    "    # If object_name is not provided, use the local file name\n",
    "    if object_name is None:\n",
    "        object_name = file_path.split('/')[-1]\n",
    "        \n",
    "    # Create an S3 client\n",
    "    s3_client = boto3.client('s3')\n",
    "    \n",
    "    try:\n",
    "        s3_client.upload_file(file_path, bucket_name, object_name)\n",
    "        print(f\"File '{file_path}' uploaded successfully to bucket '{bucket_name}' with key '{object_name}'\")\n",
    "    except Exception as e:\n",
    "        print(f'Error uploading file to S3: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'sp-test-03ebd6dd-efe7-4e49-aee5-a9d4a77fa19a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'first.txt' uploaded successfully to bucket 'sp-test-03ebd6dd-efe7-4e49-aee5-a9d4a77fa19a' with key 'folder/file.txt'\n",
      "File 'new_schema.sql' uploaded successfully to bucket 'sp-test-03ebd6dd-efe7-4e49-aee5-a9d4a77fa19a' with key 'new_schema.sql'\n"
     ]
    }
   ],
   "source": [
    "upload_file_to_s3('first.txt', bucket_name, 'folder/file.txt')\n",
    "# Using file name as object name\n",
    "upload_file_to_s3('new_schema.sql', bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List all files in s3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files_in_s3_bucket(bucket_name):\n",
    "    s3_resource = boto3.resource('s3')\n",
    "    s3_bucket = s3_resource.Bucket(bucket_name)\n",
    "    \n",
    "    files = [\n",
    "        {\n",
    "            'Key': obj.key,\n",
    "            'Last Modified': obj.last_modified,\n",
    "            'Size': obj.size\n",
    "        }\n",
    "        for obj in s3_bucket.objects.all()\n",
    "    ]\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Key': 'firstfile.txt',\n",
       "  'Last Modified': datetime.datetime(2024, 5, 23, 8, 48, 10, tzinfo=tzutc()),\n",
       "  'Size': 9},\n",
       " {'Key': 'folder/file.txt',\n",
       "  'Last Modified': datetime.datetime(2024, 5, 23, 12, 11, 1, tzinfo=tzutc()),\n",
       "  'Size': 9},\n",
       " {'Key': 'new_schema.sql',\n",
       "  'Last Modified': datetime.datetime(2024, 5, 23, 12, 11, 2, tzinfo=tzutc()),\n",
       "  'Size': 940}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_files_in_s3_bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download file from s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file_from_s3(download_path, bucket_name, object_name):\n",
    "    s3_client = boto3.client('s3')\n",
    "    \n",
    "    try:\n",
    "        s3_client.download_file(bucket_name, object_name, download_path)\n",
    "        print(f\"File '{object_name}' downloaded successfully from bucket '{bucket_name}' to '{download_path}'\")\n",
    "    except Exception as e:\n",
    "        print(f'Error downloading file from S3: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'firstfile.txt' downloaded successfully from bucket 'sp-test-03ebd6dd-efe7-4e49-aee5-a9d4a77fa19a' to './downloaded_file.txt'\n"
     ]
    }
   ],
   "source": [
    "download_file_from_s3('./downloaded_file.txt', bucket_name, 'firstfile.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
